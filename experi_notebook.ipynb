{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i'm taking this ipynb file to experiment my  code bit by bit before running the whole code once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumen\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(openai_api_key=key,model_name=\"gpt-3.5-turbo\",temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"response.json\",\"r\") as f:\n",
    "    RESPONSE_JSON=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm,prompt=quiz_evaluation_prompt,output_key=\"review\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"RESPONSE_JSON\"],output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data.txt\",\"r\") as file:\n",
    "    TEXT=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5\n",
    "SUBJECT=\"AI\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumen\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize \n",
      "the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle \n",
      "of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, \n",
      "applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. \n",
      "We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of \n",
      "interest include but are not limited to:\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for AI students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for AI students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "\n",
      "{\n",
      "\"1\": {\n",
      "\"no\": \"1\",\n",
      "\"mcq\": \"What is the focus of the workshop on Generative AI at AIMLSystems?\",\n",
      "\"options\": {\"a\": \"Building robots\", \"b\": \"Developing mobile apps\", \"c\": \"Creating Generative AI systems\", \"d\": \"Designing websites\"},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"2\": {\n",
      "\"no\": \"2\",\n",
      "\"mcq\": \"What is one of the topics of interest for the workshop on Generative AI at AIMLSystems?\",\n",
      "\"options\": {\"a\": \"Cooking recipes\", \"b\": \"Ethics in technology\", \"c\": \"Fashion trends\", \"d\": \"Sports analytics\"},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"3\": {\n",
      "\"no\": \"3\",\n",
      "\"mcq\": \"What can generative models produce, according to the text?\",\n",
      "\"options\": {\"a\": \"Realistic text, images, and video\", \"b\": \"Music albums\", \"c\": \"Cooking shows\", \"d\": \"Fashion magazines\"},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"4\": {\n",
      "\"no\": \"4\",\n",
      "\"mcq\": \"What concerns are associated with Generative AI technology?\",\n",
      "\"options\": {\"a\": \"Fairness, transparency, and accountability\", \"b\": \"Speed, accuracy, and efficiency\", \"c\": \"Color, size, and shape\", \"d\": \"Taste, smell, and touch\"},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"5\": {\n",
      "\"no\": \"5\",\n",
      "\"mcq\": \"What kind of work is invited for the workshop on Artificial Intelligence with a focus on generative AI?\",\n",
      "\"options\": {\"a\": \"Published work\", \"b\": \"Unpublished work\", \"c\": \"Fictional work\", \"d\": \"Historical work\"},\n",
      "\"correct\": \"b\"\n",
      "}\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with  get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"RESPONSE_JSON\": json.dumps(RESPONSE_JSON)\n",
    "\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize \\nthe way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle \\nof building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, \\napplications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. \\nWe invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of \\ninterest include but are not limited to:',\n",
       " 'number': 5,\n",
       " 'subject': 'AI',\n",
       " 'tone': 'simple',\n",
       " 'RESPONSE_JSON': '{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '\\n{\\n\"1\": {\\n\"no\": \"1\",\\n\"mcq\": \"What is the focus of the workshop on Generative AI at AIMLSystems?\",\\n\"options\": {\"a\": \"Building robots\", \"b\": \"Developing mobile apps\", \"c\": \"Creating Generative AI systems\", \"d\": \"Designing websites\"},\\n\"correct\": \"c\"\\n},\\n\"2\": {\\n\"no\": \"2\",\\n\"mcq\": \"What is one of the topics of interest for the workshop on Generative AI at AIMLSystems?\",\\n\"options\": {\"a\": \"Cooking recipes\", \"b\": \"Ethics in technology\", \"c\": \"Fashion trends\", \"d\": \"Sports analytics\"},\\n\"correct\": \"b\"\\n},\\n\"3\": {\\n\"no\": \"3\",\\n\"mcq\": \"What can generative models produce, according to the text?\",\\n\"options\": {\"a\": \"Realistic text, images, and video\", \"b\": \"Music albums\", \"c\": \"Cooking shows\", \"d\": \"Fashion magazines\"},\\n\"correct\": \"a\"\\n},\\n\"4\": {\\n\"no\": \"4\",\\n\"mcq\": \"What concerns are associated with Generative AI technology?\",\\n\"options\": {\"a\": \"Fairness, transparency, and accountability\", \"b\": \"Speed, accuracy, and efficiency\", \"c\": \"Color, size, and shape\", \"d\": \"Taste, smell, and touch\"},\\n\"correct\": \"a\"\\n},\\n\"5\": {\\n\"no\": \"5\",\\n\"mcq\": \"What kind of work is invited for the workshop on Artificial Intelligence with a focus on generative AI?\",\\n\"options\": {\"a\": \"Published work\", \"b\": \"Unpublished work\", \"c\": \"Fictional work\", \"d\": \"Historical work\"},\\n\"correct\": \"b\"\\n}\\n}',\n",
       " 'review': 'The complexity of the quiz questions is suitable for AI students as it covers a range of topics related to Generative AI. However, the questions could be made more engaging by incorporating real-world examples or scenarios to enhance student comprehension and application of the concepts.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'no': '1',\n",
       "  'mcq': 'What is the focus of the workshop on Generative AI at AIMLSystems?',\n",
       "  'options': {'a': 'Building robots',\n",
       "   'b': 'Developing mobile apps',\n",
       "   'c': 'Creating Generative AI systems',\n",
       "   'd': 'Designing websites'},\n",
       "  'correct': 'c'},\n",
       " '2': {'no': '2',\n",
       "  'mcq': 'What is one of the topics of interest for the workshop on Generative AI at AIMLSystems?',\n",
       "  'options': {'a': 'Cooking recipes',\n",
       "   'b': 'Ethics in technology',\n",
       "   'c': 'Fashion trends',\n",
       "   'd': 'Sports analytics'},\n",
       "  'correct': 'b'},\n",
       " '3': {'no': '3',\n",
       "  'mcq': 'What can generative models produce, according to the text?',\n",
       "  'options': {'a': 'Realistic text, images, and video',\n",
       "   'b': 'Music albums',\n",
       "   'c': 'Cooking shows',\n",
       "   'd': 'Fashion magazines'},\n",
       "  'correct': 'a'},\n",
       " '4': {'no': '4',\n",
       "  'mcq': 'What concerns are associated with Generative AI technology?',\n",
       "  'options': {'a': 'Fairness, transparency, and accountability',\n",
       "   'b': 'Speed, accuracy, and efficiency',\n",
       "   'c': 'Color, size, and shape',\n",
       "   'd': 'Taste, smell, and touch'},\n",
       "  'correct': 'a'},\n",
       " '5': {'no': '5',\n",
       "  'mcq': 'What kind of work is invited for the workshop on Artificial Intelligence with a focus on generative AI?',\n",
       "  'options': {'a': 'Published work',\n",
       "   'b': 'Unpublished work',\n",
       "   'c': 'Fictional work',\n",
       "   'd': 'Historical work'},\n",
       "  'correct': 'b'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)\n",
    "quiz.to_csv(\"machinelearning.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/sumen/OneDrive/Desktop/LLM_apps/MCQ_test_using_llms')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'no': '1',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'},\n",
       " '2': {'no': '2',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'},\n",
       " '3': {'no': '3',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(str(Path.cwd())+\"\\\\response.json\",\"r\") as f:\n",
    "    RESPONSE_JSON=json.load(f)\n",
    "RESPONSE_JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
